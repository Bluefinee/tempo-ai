/**
 * @fileoverview Gemini AI Analysis Service
 *
 * Google Gemini 2.5 Flash ã‚’ä½¿ç”¨ã—ãŸAIåˆ†æã‚µãƒ¼ãƒ“ã‚¹ã€‚
 * ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢ãƒ‡ãƒ¼ã‚¿ã®åŒ…æ‹¬çš„åˆ†æã¨ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸ
 * ã‚¢ãƒ‰ãƒã‚¤ã‚¹ç”Ÿæˆã‚’æä¾›ã—ã¾ã™ã€‚
 */

import { GoogleGenerativeAI } from '@google/generative-ai'

/**
 * Gemini AIåˆ†æãƒªã‚¯ã‚¨ã‚¹ãƒˆ
 */
export interface GeminiAnalysisRequest {
  prompt: string
  apiKey: string
  language?: 'ja' | 'en'
  maxTokens?: number
  temperature?: number
}

/**
 * Gemini AIåˆ†æã‚µãƒ¼ãƒ“ã‚¹
 */
export class GeminiAIAnalysisService {
  /**
   * Gemini 2.0 Flash ã§ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢åˆ†æã‚’ç”Ÿæˆ
   */
  static async generateHealthAnalysis(
    request: GeminiAnalysisRequest,
  ): Promise<string> {
    const {
      prompt,
      apiKey,
      maxTokens = 2000,
      temperature = 0.7,
      language = 'ja',
    } = request

    // Gemini ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
    const genAI = new GoogleGenerativeAI(apiKey)

    const model = genAI.getGenerativeModel({
      model: 'gemini-2.5-flash',
      generationConfig: {
        maxOutputTokens: maxTokens,
        temperature: 0.3,
        topP: 0.8,
        topK: 32,
      },
    })

    try {
      // Geminiç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–
      const optimizedPrompt = GeminiAIAnalysisService.optimizePromptForGemini(
        prompt,
        language,
      )

      // === GEMINI REQUEST DETAILS ===
      console.log('='.repeat(50))
      console.log('ğŸ“ GEMINI PROMPT DETAILS')
      console.log('='.repeat(50))
      console.log('ğŸ“Š ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ–‡å­—æ•°:', optimizedPrompt.length)
      console.log('ğŸ“ é€ä¿¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†…å®¹:')
      console.log(optimizedPrompt)
      console.log('âš™ï¸ Generation Config:')
      console.log('  - Model: gemini-2.5-flash')
      console.log('  - maxOutputTokens:', maxTokens)
      console.log('  - temperature:', temperature)
      console.log('='.repeat(50))

      // ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ä»˜ãã§APIå‘¼ã³å‡ºã—
      let lastError: Error | null = null
      const maxRetries = 3

      for (let attempt = 1; attempt <= maxRetries; attempt++) {
        try {
          const result = await model.generateContent(optimizedPrompt)
          const response = await result.response
          const text = response.text()

          // === GEMINI RESPONSE ANALYSIS ===
          console.log('ğŸ¤– GEMINI RESPONSE ANALYSIS')
          console.log('='.repeat(50))
          console.log('ğŸ“ Response length:', text?.length || 0)
          console.log(
            'ğŸ“ Response preview:',
            text?.substring(0, 200) || 'No text',
          )
          console.log('ğŸ§® Token usage:')
          console.log(
            '  - Prompt tokens:',
            response.usageMetadata?.promptTokenCount || 0,
          )
          console.log(
            '  - Total tokens:',
            response.usageMetadata?.totalTokenCount || 0,
          )
          console.log(
            'ğŸ Finish reason:',
            response.candidates?.[0]?.finishReason || 'unknown',
          )
          console.log('='.repeat(50))

          // ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ¤œè¨¼
          if (!text || text.trim().length === 0) {
            console.error('âŒ GEMINI RESPONSE FAILED')
            console.error('âŒ Empty text content')
            console.error('âŒ Full response object:')
            console.error(JSON.stringify(response, null, 2))
            throw new Error('Empty response from Gemini API')
          }

          console.log('âœ… Gemini API response validated successfully')
          return text
        } catch (error) {
          lastError = error as Error

          if (attempt < maxRetries) {
            // æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã§å†è©¦è¡Œ
            const delay = 2 ** attempt * 1000
            await new Promise((resolve) => setTimeout(resolve, delay))
          }
        }
      }

      throw lastError || new Error('Gemini API failed after retries')
    } catch (error) {
      console.error('Gemini API error:', error)
      throw new Error(
        `Gemini AI analysis failed: ${error instanceof Error ? error.message : 'Unknown error'}`,
      )
    }
  }

  /**
   * ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ Gemini 2.0 Flash å½¢å¼ã«æœ€é©åŒ–
   */
  private static optimizePromptForGemini(
    originalPrompt: string,
    language: string,
  ): string {
    let optimizedPrompt = originalPrompt

    // Gemini 2.0 Flash ç‰¹æœ‰ã®æœ€é©åŒ–
    if (language === 'ja') {
      optimizedPrompt +=
        '\n\né‡è¦æŒ‡ç¤º: å¿…ãšæ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚JSONå½¢å¼ã‚’å³å¯†ã«å®ˆã£ã¦ãã ã•ã„ã€‚'
    } else {
      optimizedPrompt +=
        '\n\nIMPORTANT: Respond in English. Strictly follow JSON format.'
    }

    // JSON å‡ºåŠ›ã®å¼·èª¿
    optimizedPrompt +=
      '\n\nResponse must be valid JSON only, no additional explanations or text outside JSON.'

    return optimizedPrompt
  }

  /**
   * Gemini API ã®å¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯
   */
  static async checkAvailability(apiKey: string): Promise<boolean> {
    try {
      const genAI = new GoogleGenerativeAI(apiKey)
      const model = genAI.getGenerativeModel({ model: 'gemini-2.5-flash' })

      // ç°¡å˜ãªãƒ†ã‚¹ãƒˆ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
      const result = await model.generateContent(
        'Test connection. Respond with "OK".',
      )
      const response = await result.response
      const text = response.text()

      return text.includes('OK')
    } catch {
      return false
    }
  }

  /**
   * ä½¿ç”¨é‡æƒ…å ±å–å¾—ï¼ˆæ¦‚ç®—ï¼‰
   */
  static estimateTokenUsage(prompt: string): number {
    // æ¦‚ç®—: æ—¥æœ¬èª1æ–‡å­— â‰ˆ 2-3ãƒˆãƒ¼ã‚¯ãƒ³ã€è‹±èª1å˜èª â‰ˆ 1.3ãƒˆãƒ¼ã‚¯ãƒ³
    const japaneseChars = (
      prompt.match(/[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FAF]/g) || []
    ).length
    const englishWords = prompt.split(/\s+/).length

    return Math.ceil(japaneseChars * 2.5 + englishWords * 1.3)
  }
}
